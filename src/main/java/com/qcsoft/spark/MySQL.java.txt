package com.qcsoft.spark;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.function.VoidFunction;
import org.apache.spark.sql.DataFrame;
import org.apache.spark.sql.DataFrameReader;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.RowFactory;
import org.apache.spark.sql.SQLContext;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;

import scala.Function;
import scala.Tuple2;

public class MySQL {

	public static void main(String[] args) {

		SparkConf conf = new SparkConf().setMaster("local").setAppName("SparkSQLJDBC2Mysql");

		JavaSparkContext sc = new JavaSparkContext(conf);

		SQLContext sqlContext = new JavaSQLContext(sc);


		DataFrameReader reader = sqlContext.read().format("jdbc");

		reader.option("url", "jdbc:mysql://master:3306/spark");

		reader.option("dbtable", "nameandscore");

		reader.option("driver", "com.mysql.jdbc.Driver");

		reader.option("user", "root");

		reader.option("password", "123456");



		DataFrame dataFrame1 = reader.load(); // 基于hive数据库生成的DataFrame

		dataFrame1.show();

		reader.option("dbtable", "nameandage");

		DataFrame dataFrame2 = reader.load();// 基于hive2数据库生成的DataFrame

		dataFrame2.show();

		/**
		 * 
		 * 把datafram 转化成rdd 并基于rdd 进行join操作
		 * 
		 */

		JavaPairRDD<String, Tuple2<Integer, Integer>> resultRDD = dataFrame1.javaRDD()
				.mapToPair(new PairFunction<Row, String, Integer>() {

					private static final long serialVersionUID = 1L;

					@Override

					public Tuple2<String, Integer> call(Row row) throws Exception {

						return new Tuple2<String, Integer>(row.getAs("name").toString(), (int) row.getInt(1));

					}

				}).join(dataFrame2.javaRDD().mapToPair(new PairFunction<Row, String, Integer>() {

					private static final long serialVersionUID = 1L;

					@Override

					public Tuple2<String, Integer> call(Row row) throws Exception {

						return new Tuple2<String, Integer>(row.getAs("name").toString(), (int) row.getInt(1));

					}

				}));

		JavaRDD<Row> reusltRowRDD = resultRDD.map(new Function<Tuple2<String, Tuple2<Integer, Integer>>, Row>() {

			@Override

			public Row call(Tuple2<String, Tuple2<Integer, Integer>> tuple) throws Exception {

				// TODO Auto-generated method stub

				return RowFactory.create(tuple._1, tuple._2._2, tuple._2._1);

			}

		});

		List<StructField> structFields = new ArrayList<StructField>();

		structFields.add(DataTypes.createStructField("name", DataTypes.StringType, true));

		structFields.add(DataTypes.createStructField("age", DataTypes.IntegerType, true));

		structFields.add(DataTypes.createStructField("score", DataTypes.IntegerType, true));

		// 构建StructType，用于最后DataFrame元数据的描述

		StructType structType = DataTypes.createStructType(structFields);

		DataFrame personsDF = sqlContext.createDataFrame(reusltRowRDD, structType);

		personsDF.show();

		/**
		 * 
		 * 1.当dataframe要把通过spark sql、core、ml等复杂操作后的数据写入数据库的时候 首先是权限的问题，必须
		 * 
		 * 确保数据库授权了当前操作spark sql的用户
		 * 
		 * 2.Dataframe要写数据到db 的时候，一般都不可以直接写进去，而是要转成RDD，通过RDD写数据到db中
		 * 
		 */

		personsDF.javaRDD().foreachPartition(new VoidFunction<Iterator<Row>>() {

			@Override

			public void call(Iterator<Row> t) throws Exception {
				
				Connection conn2mysql = null;
				Statement statement = null;

				try {
					conn2mysql = DriverManager.getConnection("jdbc:mysql://master:3306/spark", "root", "123456");
					statement = conn2mysql.createStatement();

					while (t.hasNext()) {
						String sql = "insert into nameagescore (name,age,score) values (";
						Row row = t.next();
						String name = row.getAs("name");
						int age = row.getInt(1);
						int score = row.getInt(2);
						sql += "'" + name + "'," + "'" + age + "'," + "'" + score + "')";
						statement.execute(sql);

					}

				} catch (SQLException e) {

					e.printStackTrace();

				} finally {
					if (conn2mysql != null) {
						conn2mysql.close();
					}
					if (statement != null) {
						statement.close();
					}

				}

			}

		});

	}

}
